{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of NLP_Database_Fusion_Single_Words.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ykum9sissMgq",
        "colab_type": "text"
      },
      "source": [
        "Importing all essential libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQfX9CjYsPga",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "ea72cedf-d471-4196-b245-299d5c9720c0"
      },
      "source": [
        "!pip install faker\n",
        "#Importing all libraries\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "import numpy as np\n",
        "import pickle as pickle\n",
        "import subprocess,io\n",
        "from time import time\n",
        "from sklearn.decomposition import PCA\n",
        "from itertools import repeat\n",
        "from faker import Faker\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "\n",
        "#Optional Libraries\n",
        "#from gensim.models import word2vec\n",
        "#import gensim.downloader as api\n",
        "#from gensim.models import KeyedVectors\n",
        "\n",
        "\n",
        "#Glove pretrained word embeddings: https://nlp.stanford.edu/projects/glove/"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: faker in /usr/local/lib/python3.6/dist-packages (4.1.2)\n",
            "Requirement already satisfied: text-unidecode==1.3 in /usr/local/lib/python3.6/dist-packages (from faker) (1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.6/dist-packages (from faker) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.4->faker) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYH9rFjANjyA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f4b1d4ef-8e52-43b3-c5d6-5d82c07d7af8"
      },
      "source": [
        "#Connect your drive as file system (If you have your files on drive)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2phL3B7s5Yv",
        "colab_type": "text"
      },
      "source": [
        "Word Embeddings part\n",
        "(Pre-trained embeddings used: Glove)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Reducing the vector dimensions unsing PCA\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSx3vuRJqGdU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This function is present in python program file, due to location issues I have maintained one copy here as well\n",
        "#Reducing Glove word embeddings from 50 to 10 dimensions\n",
        "Glove = {}\n",
        "with io.open('/content/drive/My Drive/NLP_Data/glove.6B.50d.txt', encoding='utf8') as f:\n",
        "#f = open('/content/drive/mydrive/glove.6B.50d.txt')\n",
        "\n",
        "    print(\"Loading Glove vectors.\")\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        Glove[word] = coefs\n",
        "    f.close()\n",
        "\n",
        "    print(\"Done.\")\n",
        "    X_train = []\n",
        "    X_train_names = []\n",
        "    for x in Glove:\n",
        "            X_train.append(Glove[x])\n",
        "            X_train_names.append(x)\n",
        "\n",
        "    X_train = np.asarray(X_train)\n",
        "    pca_embeddings = {}\n",
        "\n",
        "# PCA to get Top Components\n",
        "    pca =  PCA(n_components = 50)\n",
        "    X_train = X_train - np.mean(X_train)\n",
        "    X_fit = pca.fit_transform(X_train)\n",
        "    U1 = pca.components_\n",
        "\n",
        "    z = []\n",
        "\n",
        "# Removing Projections on Top Components\n",
        "    for i, x in enumerate(X_train):\n",
        "\t    for u in U1[0:7]:        \n",
        "        \t    x = x - np.dot(u.transpose(),x) * u \n",
        "\t    z.append(x)\n",
        "\n",
        "    z = np.asarray(z)\n",
        "\n",
        "# PCA Dim Reduction\n",
        "    pca =  PCA(n_components = 10)\n",
        "    X_train = z - np.mean(z)\n",
        "    X_new_final = pca.fit_transform(X_train)\n",
        "\n",
        "\n",
        "# PCA to do Post-Processing Again\n",
        "    pca =  PCA(n_components = 10)\n",
        "    X_new = X_new_final - np.mean(X_new_final)\n",
        "    X_new = pca.fit_transform(X_new)\n",
        "    Ufit = pca.components_\n",
        "\n",
        "    X_new_final = X_new_final - np.mean(X_new_final)\n",
        "\n",
        "    final_pca_embeddings = {}\n",
        "    embedding_file = open('/content/drive/My Drive/NLP_Data/pca_embed2.txt', 'w')\n",
        "\n",
        "    for i, x in enumerate(X_train_names):\n",
        "      final_pca_embeddings[x] = X_new_final[i]\n",
        "      embedding_file.write(\"%s\\t\" % x)\n",
        "      for u in Ufit[0:7]:\n",
        "        final_pca_embeddings[x] = final_pca_embeddings[x] - np.dot(u.transpose(),final_pca_embeddings[x]) * u \n",
        "\n",
        "      for t in final_pca_embeddings[x]:\n",
        "        embedding_file.write(\"%f\\t\" % t)\n",
        "        \n",
        "      embedding_file.write(\"\\n\")\n",
        "\n",
        "\n",
        "    print(\"Reduced the dimensionality of the vector to 10 dimensions! \\nPlease check pca_embed2.txt file\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWptWbI8q9Sf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This function is present in python program file, due to location issues I have maintained one copy here as well\n",
        "#Function to get 10 dimensional vector from txt file\n",
        "def get_vector(given_word):\n",
        "  Glove = {}\n",
        "  with io.open('/content/drive/My Drive/NLP_Data/pca_embed2.txt', encoding='utf8') as f:\n",
        "  #f = open('/content/drive/My Drive/NLP_Data/pca_embed2.txt')\n",
        "\n",
        "      #print(\"Loading Glove vectors.\")\n",
        "      for line in f:\n",
        "          values = line.split()\n",
        "          word = values[0]\n",
        "          if word == given_word:\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            given_word_vector = coefs\n",
        "            break\n",
        "  f.close()\n",
        "  return given_word_vector"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRhXBMkprMHF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Getting Vectors for available posts\n",
        "engineer_vector = get_vector('engineer')\n",
        "manager_vector = get_vector('manager')\n",
        "developer_vector = get_vector('developer')\n",
        "ceo_vector = get_vector('ceo')\n",
        "cto_vector = get_vector('cto')\n",
        "coo_vector = get_vector('coo')\n",
        "waiter_vector = get_vector('waiter')\n",
        "\n",
        "#Getting Vectors for available cities\n",
        "victoria_vector = get_vector('victoria')\n",
        "vancouver_vector = get_vector('vancouver')\n",
        "delhi_vector = get_vector('delhi')\n",
        "pune_vector = get_vector('pune')\n",
        "ottawa_vector = get_vector('ottawa')\n",
        "toronto_vector = get_vector('toronto')\n",
        "mumbai_vector = get_vector('mumbai')\n",
        "\n",
        "#Stored these vectors in CSV Files\n",
        "#File names:\n",
        "#1. table1_name_post_city.csv\n",
        "#2. table2_vectors_for_post_city.csv\n",
        "#3. table3_vectors_for_posts.csv\n",
        "#4. table4_vectors_for_cities.csv"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrTl-VK8rMJ7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "017c557e-6185-412c-a326-ec8c6bd4165c"
      },
      "source": [
        "#This function is present in python program file, due to location issues I have maintained one copy here as well\n",
        "\n",
        "#Defining Cosine Similarity Function\n",
        "def cos_sim(a, b):\n",
        "    \"\"\"Takes 2 vectors a, b and returns the cosine similarity according \n",
        "    to the definition of the dot product\n",
        "    \"\"\"\n",
        "    dot_product = np.dot(a, b)\n",
        "    norm_a = np.linalg.norm(a)\n",
        "    norm_b = np.linalg.norm(b)\n",
        "    return dot_product / (norm_a * norm_b)\n",
        "\n",
        "#Testing the function\n",
        "similarity = cos_sim(engineer_vector,developer_vector)\n",
        "print(\"Similarity between Engineer and Developer:\",similarity)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Similarity between Engineer and Developer: 0.79248005\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Umwm7_4Ns94g",
        "colab_type": "text"
      },
      "source": [
        "Database creation part\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dkq6wH00rHEA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This function is present in python program file, due to location issues I have maintained one copy here as well\n",
        "\n",
        "#Generating Data\n",
        "def get_data(n,j):\n",
        "  #Getting fake names\n",
        "  fake = Faker()\n",
        "  name_df = [fake.name() for i in range(n)]\n",
        "  name_df = pd.DataFrame((name_df),columns=['name'])\n",
        "\n",
        "  #Dataframe with Vectors for respective posts and post\n",
        "  data = pd.read_csv (r'/content/drive/My Drive/NLP_Data/table3_vectors_for_posts.csv')   \n",
        "  orig_post_df = pd.DataFrame(data, columns= ['pi1','pi2','pi3','pi4','pi5','pi6','pi7','pi8','pi9','pi10','post'])\n",
        "  post_df = orig_post_df.iloc[:,:]\n",
        "  #print(df3)\n",
        "\n",
        "  #Dataframe with Vectors for respective cities and city\n",
        "  data = pd.read_csv (r'/content/drive/My Drive/NLP_Data/table4_vectors_for_cities.csv')   \n",
        "  orig_city_df = pd.DataFrame(data, columns= ['ci1','ci2','ci3','ci4','ci5','ci6','ci7','ci8','ci9','ci10','city'])\n",
        "  city_df = orig_city_df.iloc[:,:]\n",
        "  #print(df4)\n",
        "\n",
        "    #Shuffling and storing the data n times\n",
        "  new_city_df = city_df\n",
        "  new_post_df = post_df\n",
        "\n",
        "  for i in range(int(n/7)):\n",
        "    city_df = shuffle(city_df)\n",
        "    post_df = shuffle(post_df)\n",
        "    new_city_df = pd.concat([new_city_df, city_df], axis=0)\n",
        "    new_post_df = pd.concat([new_post_df, post_df], axis=0)\n",
        "\n",
        "  #Getting n number of data\n",
        "  normal_city_df = new_city_df.iloc[:,10]\n",
        "  normal_post_df = new_post_df.iloc[:,10]\n",
        "  n_city_df = new_city_df.iloc[:,:-1]\n",
        "  n_post_df = new_post_df.iloc[:,:-1]\n",
        "\n",
        "  n_city_df= new_city_df.head(n)\n",
        "  n_post_df= new_post_df.head(n)\n",
        "  normal_city_df= normal_city_df.head(n)\n",
        "  normal_post_df= normal_post_df.head(n)\n",
        "\n",
        "  #Resetting index\n",
        "  n_city_df.reset_index(drop=True, inplace=True)\n",
        "  n_post_df.reset_index(drop=True, inplace=True)\n",
        "  normal_city_df.reset_index(drop=True, inplace=True)\n",
        "  normal_post_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "  #Dataframe ready for table 1 with name, post and city word embeddings\n",
        "  df1 = pd.concat([name_df,n_post_df,n_city_df], axis=1)\n",
        "  normal_df1 = pd.concat([name_df,normal_post_df,normal_city_df], axis=1)\n",
        "  #print(df1)\n",
        "\n",
        "  #Shuffling and resetting index for table 2 \n",
        "  new_city_df = shuffle(new_city_df)\n",
        "  new_post_df = shuffle(new_post_df)\n",
        "\n",
        "  normal2_city_df = new_city_df.iloc[:,10]\n",
        "  normal2_post_df = new_post_df.iloc[:,10]\n",
        "  new_city_df = new_city_df.iloc[:,:-1]\n",
        "  new_post_df = new_post_df.iloc[:,:-1]\n",
        "\n",
        "  new_city_df= new_city_df.head(j)\n",
        "  new_post_df= new_post_df.head(j)\n",
        "  normal2_city_df= normal_city_df.head(j)\n",
        "  normal2_post_df= normal_post_df.head(j)\n",
        "\n",
        "  new_city_df.reset_index(drop=True, inplace=True)\n",
        "  new_post_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "  #Dataframe ready for table 2 with post and city\n",
        "  df2 = pd.concat([new_post_df,new_city_df], axis=1)\n",
        "  normal_df2 = pd.concat([normal2_post_df,normal2_city_df], axis=1)\n",
        "  #print(df2)\n",
        "\n",
        "  #Creating database\n",
        "  connection = sqlite3.connect(\"position_city_database_with_embeddings.db\") \n",
        "  crsr = connection.cursor() \n",
        "\n",
        "  #Comment the table creation and insertion of data into the table if the database is already created once.\n",
        "  #Creating table1 with name, embeddings of post, and embeddings of city\n",
        "  crsr.execute('CREATE TABLE name_post_city (NAME nvarchar(50),pi1 float,pi2 float,pi3 float,pi4 float,pi5 float,pi6 float,pi7 float,pi8 float,pi9 float,pi10 float, ci1 float,ci2 float,ci3 float,ci4 float,ci5 float,ci6 float,ci7 float,ci8 float,ci9 float,ci10 float, FOREIGN KEY (ci1,ci2,ci3,ci4,ci5,ci6,ci7,ci8,ci9,ci10) REFERENCES em_city_name(ci1,ci2,ci3,ci4,ci5,ci6,ci7,ci8,ci9,ci10), FOREIGN KEY (pi1,pi2,pi3,pi4,pi5,pi6,pi7,pi8,pi9,pi10) REFERENCES em_post_city(pi1,pi2,pi3,pi4,pi5,pi6,pi7,pi8,pi9,pi10))')\n",
        "  df1.to_sql('name_post_city', connection, if_exists='replace', index = False)\n",
        "  crsr.execute('''SELECT * FROM name_post_city''')\n",
        "  print(\"Table 1: Name_Post_City Data\")\n",
        "  # for row in crsr.fetchall():\n",
        "  #     print (row)\n",
        "\n",
        "  #Creating normal table1 with name,post, and city\n",
        "  crsr.execute('CREATE TABLE normal_name_post_city (NAME nvarchar(50),pi1 float,pi2 float,pi3 float,pi4 float,pi5 float,pi6 float,pi7 float,pi8 float,pi9 float,pi10 float, ci1 float,ci2 float,ci3 float,ci4 float,ci5 float,ci6 float,ci7 float,ci8 float,ci9 float,ci10 float, FOREIGN KEY (ci1,ci2,ci3,ci4,ci5,ci6,ci7,ci8,ci9,ci10) REFERENCES em_city_name(ci1,ci2,ci3,ci4,ci5,ci6,ci7,ci8,ci9,ci10), FOREIGN KEY (pi1,pi2,pi3,pi4,pi5,pi6,pi7,pi8,pi9,pi10) REFERENCES em_post_city(pi1,pi2,pi3,pi4,pi5,pi6,pi7,pi8,pi9,pi10))')\n",
        "  normal_df1.to_sql('normal_name_post_city', connection, if_exists='replace', index = False)\n",
        "  crsr.execute('''SELECT * FROM normal_name_post_city''')\n",
        "  print(\"Normal Table 1: Normal_Name_Post_City Data\")\n",
        "  # for row in crsr.fetchall():\n",
        "  #     print (row)\n",
        "\n",
        "  #Creating table2 with embeddings of post and embeddings of city\n",
        "  crsr.execute('CREATE TABLE post_city (pi1 float,pi2 float,pi3 float,pi4 float,pi5 float,pi6 float,pi7 float,pi8 float,pi9 float,pi10 float, ci1 float,ci2 float,ci3 float,ci4 float,ci5 float,ci6 float,ci7 float,ci8 float,ci9 float,ci10 float, FOREIGN KEY (ci1,ci2,ci3,ci4,ci5,ci6,ci7,ci8,ci9,ci10) REFERENCES em_city_name(ci1,ci2,ci3,ci4,ci5,ci6,ci7,ci8,ci9,ci10), FOREIGN KEY (pi1,pi2,pi3,pi4,pi5,pi6,pi7,pi8,pi9,pi10) REFERENCES em_post_city(pi1,pi2,pi3,pi4,pi5,pi6,pi7,pi8,pi9,pi10))')\n",
        "  df2.to_sql('post_city', connection, if_exists='replace', index = False)\n",
        "  print(\"\\nTable 2: Post_City Data\")\n",
        "  crsr.execute('''SELECT * FROM post_city''')\n",
        "  # for row in crsr.fetchall():\n",
        "  #     print (row)\n",
        "  \n",
        "\n",
        "  #Creating normal table2 with post and city\n",
        "  crsr.execute('CREATE TABLE normal_post_city (pi1 float,pi2 float,pi3 float,pi4 float,pi5 float,pi6 float,pi7 float,pi8 float,pi9 float,pi10 float, ci1 float,ci2 float,ci3 float,ci4 float,ci5 float,ci6 float,ci7 float,ci8 float,ci9 float,ci10 float, FOREIGN KEY (ci1,ci2,ci3,ci4,ci5,ci6,ci7,ci8,ci9,ci10) REFERENCES em_city_name(ci1,ci2,ci3,ci4,ci5,ci6,ci7,ci8,ci9,ci10), FOREIGN KEY (pi1,pi2,pi3,pi4,pi5,pi6,pi7,pi8,pi9,pi10) REFERENCES em_post_city(pi1,pi2,pi3,pi4,pi5,pi6,pi7,pi8,pi9,pi10))')\n",
        "  normal_df2.to_sql('normal_post_city', connection, if_exists='replace', index = False)\n",
        "  print(\"\\nNormal Table 2: Normal_Post_City Data\")\n",
        "  crsr.execute('''SELECT * FROM normal_post_city''')\n",
        "  # for row in crsr.fetchall():\n",
        "  #     print (row)\n",
        "\n",
        "  #Creating table3 with embeddings of post and name of posts\n",
        "  crsr.execute('CREATE TABLE em_post_name (pi1 float,pi2 float,pi3 float,pi4 float,pi5 float,pi6 float,pi7 float,pi8 float,pi9 float,pi10 float, post nvarchar(50), PRIMARY KEY(pi1,pi2,pi3,pi4,pi5,pi6,pi7,pi8,pi9,pi10))')\n",
        "  orig_post_df.to_sql('em_post_name', connection, if_exists='replace', index = False)\n",
        "  print(\"\\nTable 3: Em_Post_Name Data\")\n",
        "  crsr.execute('''SELECT * FROM em_post_name''')\n",
        "  # for row in crsr.fetchall():\n",
        "  #     print (row)\n",
        "\n",
        "  #Creating table4 with embeddings of city and name of cities\n",
        "  crsr.execute('CREATE TABLE em_city_name (ci1 float,ci2 float,ci3 float,ci4 float,ci5 float,ci6 float,ci7 float,ci8 float,ci9 float,ci10 float, city nvarchar(50), PRIMARY KEY(ci1,ci2,ci3,ci4,ci5,ci6,ci7,ci8,ci9,ci10))')\n",
        "  orig_city_df.to_sql('em_city_name', connection, if_exists='replace', index = False)\n",
        "  print(\"\\nTable 4: Em_City_Name Data\")\n",
        "  crsr.execute('''SELECT * FROM em_city_name''')\n",
        "  # for row in crsr.fetchall():\n",
        "  #     print (row)\n",
        "\n",
        "  connection.commit()\n",
        "\n",
        "  #Execute the following line to print all the SQL queries when executed\n",
        "  #connection.set_trace_callback(print)\n",
        "\n",
        "  #Incase you want to drop all tables:\n",
        "  #crsr.execute('DROP TABLE name_post_city')\n",
        "  #crsr.execute('DROP TABLE post_city')\n",
        "  #crsr.execute('DROP TABLE em_post_name')\n",
        "  #crsr.execute('DROP TABLE em_city_name')\n",
        "  #connection.commit()  \n",
        "\n",
        "get_data(1000000,1000000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8YMJdSCAo9l",
        "colab_type": "text"
      },
      "source": [
        "Function for calculating cosine similarity on:\n",
        "\n",
        "---\n",
        "1. Posts (Engineer, Developer, etc)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXcWiAVn5wvn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "connection = sqlite3.connect(\"position_city_database_with_embeddings.db\") \n",
        "crsr = connection.cursor() \n",
        "\n",
        "#This function is present in python program file, due to location issues I have maintained one copy here as well\n",
        "def sel_func_post(q,threshold,list_type):\n",
        "  crsr.execute(\"select pi1,pi2,pi3,pi4,pi5,pi6,pi7,pi8,pi9,pi10 from em_post_name where post ='%s'\" %q)\n",
        "  q_vect = crsr.fetchall()\n",
        "  crsr.execute(\"select pi1,pi2,pi3,pi4,pi5,pi6,pi7,pi8,pi9,pi10,post from em_post_name\")\n",
        "  t_vect = crsr.fetchall()\n",
        "  vect_t = [tuple(list(x)[0:10]) for x in t_vect] # Getting all vectors in em_post_name\n",
        "  vect_names = [list(x).pop(-1) for x in t_vect] # Getting all the corresponding post names to the vectors\n",
        "  #print(vect_t) # Used to print all vectors in em_post_name\n",
        "  #print(vect_names) # Used to print all the corresponding posts to the vectors\n",
        "  similarity_array = [cos_sim(q_vect, x)[0] for x in vect_t] # Getting similarity scores for all vectors in table\n",
        "  #print(similarity_array) # Used to print similary between vectors\n",
        "  a = np.array(similarity_array)\n",
        "  index = np.where(a > threshold)[0] # Getting index of all the post which are having similar value > threshold\n",
        "  #print(index) # Printing indexes \n",
        "  new_vect_t = [vect_t[x] for x in index] # Getting new vectors according to those indexes\n",
        "  if list_type==1:\n",
        "    vect_name_list = [vect_names[i] for i in index] \n",
        "    return vect_name_list #This is to return the name of the cities it found to be similar\n",
        "  #print(new_vect_t) # Printing the new vector\n",
        "  #print(list(np.array(vect_t)[index][0])) # Checking the element\n",
        "  join_list = []\n",
        "  for x in range(0,len(new_vect_t[0])):\n",
        "    join_list.append(tuple([i[x] for i in new_vect_t])) # Joining the new vectors together in a list\n",
        "  #print(join_list) # To print the join_list\n",
        "  return join_list # Returning the join_list\n",
        "\n",
        "# Executing the function\n",
        "\n",
        "t = 0.85 # Defining threshold (You can change according to your requirements)\n",
        "sel_func_post('ceo',t,0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8WnWEImA2YH",
        "colab_type": "text"
      },
      "source": [
        "Function for calculating cosine similarity on:\n",
        "\n",
        "---\n",
        "2. Cities (Victoria, Pune, etc)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXbvP13TH7jd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This function is present in python program file, due to location issues I have maintained one copy here as well\n",
        "connection = sqlite3.connect(\"position_city_database_with_embeddings.db\") \n",
        "crsr = connection.cursor() \n",
        "def sel_func_city(q,threshold,list_type):\n",
        "  crsr.execute(\"select ci1,ci2,ci3,ci4,ci5,ci6,ci7,ci8,ci9,ci10 from em_city_name where city ='%s'\" %q)\n",
        "  q_vect = crsr.fetchall()\n",
        "  crsr.execute(\"select ci1,ci2,ci3,ci4,ci5,ci6,ci7,ci8,ci9,ci10,city from em_city_name\")\n",
        "  t_vect = crsr.fetchall()\n",
        "  vect_t = [tuple(list(x)[0:10]) for x in t_vect] # Getting all vectors in em_city_name\n",
        "  vect_names = [list(x).pop(-1) for x in t_vect] # Getting all the corresponding city names to the vectors\n",
        "  #print(vect_t) # Used to print all vectors in em_post_name\n",
        "  #print(vect_names) # Used to print all the corresponding posts to the vectors\n",
        "  similarity_array = [cos_sim(q_vect, x)[0] for x in vect_t] # Getting similarity scores for all vectors in table\n",
        "  #print(similarity_array) # Used to print similary between vectors\n",
        "  a = np.array(similarity_array) \n",
        "  index = np.where(a > threshold)[0] # Getting index of all the post which are having similar value > threshold\n",
        "  #print(index) # Printing indexes \n",
        "  new_vect_t = [vect_t[x] for x in index] # Getting new vectors according to those indexes\n",
        "  if list_type == 1:\n",
        "    vect_name_list = [vect_names[i] for i in index] \n",
        "    return vect_name_list #This is to return the name of the cities it found to be similar\n",
        "  #print(new_vect_t) # Printing the new vector\n",
        "  #print(list(np.array(vect_t)[index][0])) # Checking the element\n",
        "  join_list = []\n",
        "  for x in range(0,len(new_vect_t[0])):\n",
        "    join_list.append(tuple([i[x] for i in new_vect_t]))  # Joining the new vectors together in a list\n",
        "  #print(join_list) # To print the join_list\n",
        "  return join_list # Returning the join_list\n",
        "\n",
        "# Executing the function\n",
        "\n",
        "t = 0.82 # Defining threshold (You can change according to your requirements)\n",
        "sel_func_city('vancouver',t,0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlJ7PJMQBErV",
        "colab_type": "text"
      },
      "source": [
        "Joining two tables according to word cosine similarities\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSAMjVi1cl03",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "connection = sqlite3.connect(\"position_city_database_with_embeddings.db\") \n",
        "crsr = connection.cursor() \n",
        "def makeqmarks(i):\n",
        "    return ', '.join(repeat('?', i))\n",
        "\n",
        "#placeholder = '?'\n",
        "#format_strings = ','.join(['%s'] * len(join_list[0]))\n",
        "\n",
        "\n",
        "def join_table_fun_city(join_list):\n",
        "\n",
        "# ************* Join table query *************\n",
        "  queryc = 'SELECT b.NAME, d.post, c.city \\\n",
        "  FROM em_post_name d, em_city_name c, post_city a \\\n",
        "  INNER JOIN name_post_city b \\\n",
        "  ON a.ci1 = b.ci1 AND \\\n",
        "  a.ci2 = b.ci2 AND \\\n",
        "  a.ci3 = b.ci3 AND \\\n",
        "  a.ci4 = b.ci4 AND \\\n",
        "  a.ci5 = b.ci5 AND \\\n",
        "  a.ci6 = b.ci6 AND \\\n",
        "  a.ci7 = b.ci7 AND \\\n",
        "  a.ci8 = b.ci8 AND \\\n",
        "  a.ci9 = b.ci9 AND \\\n",
        "  a.ci10 = b.ci10 \\\n",
        "  WHERE \\\n",
        "  a.ci1 = c.ci1 AND \\\n",
        "  a.ci2 = c.ci2 AND \\\n",
        "  a.ci3 = c.ci3 AND \\\n",
        "  a.ci4 = c.ci4 AND \\\n",
        "  a.ci5 = c.ci5 AND \\\n",
        "  a.ci6 = c.ci6 AND \\\n",
        "  a.ci7 = c.ci7 AND \\\n",
        "  a.ci8 = c.ci8 AND \\\n",
        "  a.ci9 = c.ci9 AND \\\n",
        "  a.ci10 = c.ci10 AND \\\n",
        "  a.pi1 = d.pi1 AND \\\n",
        "  a.pi2 = d.pi2 AND \\\n",
        "  a.pi3 = d.pi3 AND \\\n",
        "  a.pi4 = d.pi4 AND \\\n",
        "  a.pi5 = d.pi5 AND \\\n",
        "  a.pi6 = d.pi6 AND \\\n",
        "  a.pi7 = d.pi7 AND \\\n",
        "  a.pi8 = d.pi8 AND \\\n",
        "  a.pi9 = d.pi9 AND \\\n",
        "  a.pi10 = d.pi10 AND \\\n",
        "  a.ci1 IN (%s) AND \\\n",
        "  a.ci2 IN (%s) AND \\\n",
        "  a.ci3 IN (%s) AND \\\n",
        "  a.ci4 IN (%s) AND \\\n",
        "  a.ci5 IN (%s) AND \\\n",
        "  a.ci6 IN (%s) AND \\\n",
        "  a.ci7 IN (%s) AND \\\n",
        "  a.ci8 IN (%s) AND \\\n",
        "  a.ci9 IN (%s) AND \\\n",
        "  a.ci10 IN (%s);' \\\n",
        "  % (makeqmarks(len(join_list[0])), makeqmarks(len(join_list[1])), makeqmarks(len(join_list[2])),makeqmarks(len(join_list[3])),makeqmarks(len(join_list[4])),makeqmarks(len(join_list[5])),makeqmarks(len(join_list[6])),makeqmarks(len(join_list[7])),makeqmarks(len(join_list[8])),makeqmarks(len(join_list[9])))\n",
        "  #print(join_list[0]) # To check the elements in 0th index\n",
        "  return queryc\n",
        "\n",
        "def join_table_fun_post(join_list):\n",
        "\n",
        "# ************* Join table query *************\n",
        "  queryp = 'SELECT b.NAME, d.post, c.city \\\n",
        "  FROM em_post_name d, em_city_name c, post_city a \\\n",
        "  INNER JOIN name_post_city b \\\n",
        "  ON a.ci1 = b.ci1 AND \\\n",
        "  a.pi2 = b.pi2 AND \\\n",
        "  a.pi3 = b.pi3 AND \\\n",
        "  a.pi4 = b.pi4 AND \\\n",
        "  a.pi5 = b.pi5 AND \\\n",
        "  a.pi6 = b.pi6 AND \\\n",
        "  a.pi7 = b.pi7 AND \\\n",
        "  a.pi8 = b.pi8 AND \\\n",
        "  a.pi9 = b.pi9 AND \\\n",
        "  a.pi10 = b.pi10 \\\n",
        "  WHERE \\\n",
        "  a.ci1 = c.ci1 AND \\\n",
        "  a.ci2 = c.ci2 AND \\\n",
        "  a.ci3 = c.ci3 AND \\\n",
        "  a.ci4 = c.ci4 AND \\\n",
        "  a.ci5 = c.ci5 AND \\\n",
        "  a.ci6 = c.ci6 AND \\\n",
        "  a.ci7 = c.ci7 AND \\\n",
        "  a.ci8 = c.ci8 AND \\\n",
        "  a.ci9 = c.ci9 AND \\\n",
        "  a.ci10 = c.ci10 AND \\\n",
        "  a.pi1 = d.pi1 AND \\\n",
        "  a.pi2 = d.pi2 AND \\\n",
        "  a.pi3 = d.pi3 AND \\\n",
        "  a.pi4 = d.pi4 AND \\\n",
        "  a.pi5 = d.pi5 AND \\\n",
        "  a.pi6 = d.pi6 AND \\\n",
        "  a.pi7 = d.pi7 AND \\\n",
        "  a.pi8 = d.pi8 AND \\\n",
        "  a.pi9 = d.pi9 AND \\\n",
        "  a.pi10 = d.pi10 AND \\\n",
        "  a.pi1 IN (%s) AND \\\n",
        "  a.pi2 IN (%s) AND \\\n",
        "  a.pi3 IN (%s) AND \\\n",
        "  a.pi4 IN (%s) AND \\\n",
        "  a.pi5 IN (%s) AND \\\n",
        "  a.pi6 IN (%s) AND \\\n",
        "  a.pi7 IN (%s) AND \\\n",
        "  a.pi8 IN (%s) AND \\\n",
        "  a.pi9 IN (%s) AND \\\n",
        "  a.pi10 IN (%s);' \\\n",
        "  % (makeqmarks(len(join_list[0])), makeqmarks(len(join_list[1])), makeqmarks(len(join_list[2])),makeqmarks(len(join_list[3])),makeqmarks(len(join_list[4])),makeqmarks(len(join_list[5])),makeqmarks(len(join_list[6])),makeqmarks(len(join_list[7])),makeqmarks(len(join_list[8])),makeqmarks(len(join_list[9])))\n",
        "  #print(join_list[0]) # To check the elements in 0th index\n",
        "\n",
        "  return queryp\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lixI5bowa50s",
        "colab_type": "text"
      },
      "source": [
        "Executing the SQL join query and displaying the time taken to execute the query"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XddGBJus2CWD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ************* Getting Joined List and Calling the function *************\n",
        "\n",
        "join_list = sel_func_city('vancouver', 0.82,0) # Getting locations which having similarity score of more than .85 with 'Victoria'\n",
        "queryc = join_table_fun_city(join_list)\n",
        "#join_list = sel_func_post('engineer', 0.82,0)\n",
        "#queryp = join_table_fun_post(join_list)\n",
        "#print(join_list)\n",
        "\n",
        "\n",
        "# ************* Executing and Displaying the Query *************\n",
        "\n",
        "#Getting the execution time\n",
        "tic = time()\n",
        "#Query for city\n",
        "crsr.execute(queryc, join_list[0] + join_list[1] + join_list[2] + join_list[3] + join_list[4] + join_list[5] + join_list[6] + join_list[7] + join_list[8] + join_list[9])\n",
        "#Query for post\n",
        "#crsr.execute(queryp, join_list[0] + join_list[1] + join_list[2] + join_list[3] + join_list[4] + join_list[5] + join_list[6] + join_list[7] + join_list[8] + join_list[9])\n",
        "toc = time()\n",
        "ot = toc-tic\n",
        "\n",
        "#To print the query output\n",
        "#for row in crsr.fetchall():\n",
        "#    print (row)\n",
        "print(\"Execution time: \",(ot)) \n",
        "\n",
        "# Actual Generated Query\n",
        "# SELECT b.name, c.city, d.post FROM em_city_name c, em_post_name d, post_city a INNER JOIN name_post_city b ON a.ci1 = b.ci1 AND a.ci2 = b.ci2 AND a.ci3 = b.ci3 AND a.ci4 = b.ci4 AND a.ci5 = b.ci5 AND a.ci6 = b.ci6 AND a.ci7 = b.ci7 AND a.ci8 = b.ci8 AND a.ci9 = b.ci9 AND a.ci10 = b.ci10 WHERE a.ci1 IN (0.0, 0.0, 0.0) AND a.ci2 IN (0.0, 1.0e-06, 1.0e-06) AND a.ci3 IN (1.0e-06, 0.0, 0.0) AND a.ci4 IN (-1.0e-06, -1.0e-06, -1.0e-06) AND a.ci5 IN (-7.0e-06, -4.0e-06, -5.0e-06) AND a.ci6 IN (5.0e-06, -1.0e-06, 0.0) AND a.ci7 IN (1.2e-05, 3.0e-06, 7.0e-06) AND a.ci8 IN (0.457, 0.215, 0.324) AND a.ci9 IN (1.49, 1.22, 1.28) AND a.ci10 IN (1.24, 0.192, 0.472);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeVmSSwTib1y",
        "colab_type": "text"
      },
      "source": [
        "Evaluating the Quality(Accuracy)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3SWG8e_iSZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Checking the model\n",
        "def check_accuracy(join_list, expected_output):\n",
        "  if join_list == expected_output:\n",
        "    a = (len(join_list) / len(expected_output))*100\n",
        "    print(\"Accuracy =\",a)\n",
        "  else:\n",
        "    difference = set(expected_output).symmetric_difference(set(join_list))\n",
        "    list_difference = list(difference)\n",
        "    #print(list_difference)\n",
        "    intersection = set(expected_output).intersection(set(join_list))\n",
        "    list_similarity = list(intersection)\n",
        "    #print(list_similarity)\n",
        "    out_off = len(list_difference) + len(list_similarity)\n",
        "    #print(out_off)\n",
        "    #print(list_similarity)\n",
        "    a = (len(list_similarity) / out_off)*100\n",
        "    print(\"Accuracy =\",a,\"%\")\n",
        "\n",
        "t = 0.82 #Threshold is set to 0.82\n",
        "\n",
        "#List for cities\n",
        "join_list = sel_func_city('vancouver', t,1)\n",
        "expected_output = ['victoria', 'vancouver', 'ottawa', 'toronto']\n",
        "\n",
        "#List for posts\n",
        "#join_list = sel_func_post('engineer',t,1)\n",
        "#expected_output = ['engineer', 'developer']\n",
        "\n",
        "#Calling the function\n",
        "check_accuracy(join_list,expected_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mMHwwJ0ik4d",
        "colab_type": "text"
      },
      "source": [
        "Calculating the execution time of the query with the regular approach\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YM5zceJNiSwD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Calculating execution time for regular query\n",
        "connection = sqlite3.connect(\"position_city_database_with_embeddings.db\") \n",
        "crsr = connection.cursor() \n",
        "\n",
        "#Getting the execution time\n",
        "tick = time()\n",
        "#Change the expected ouput list with the IN parameters in the query\n",
        "\n",
        "#Query for post\n",
        "#crsr.execute(\"SELECT b.NAME, a.post, a.city FROM  normal_post_city a INNER JOIN normal_name_post_city b ON a.post = b.post where a.post IN ('engineer','developer')\")\n",
        "\n",
        "#Query for city\n",
        "crsr.execute(\"SELECT b.NAME, a.post, a.city FROM  normal_post_city a INNER JOIN normal_name_post_city b ON a.city = b.city where a.city IN ('victoria', 'vancouver', 'ottawa', 'toronto')\")\n",
        "\n",
        "tock = time()\n",
        "ora = tock-tick\n",
        "\n",
        "#To print the query output\n",
        "#for row in crsr.fetchall():\n",
        "#    print (row) \n",
        "print(\"Regular Approach Execution time: \",(ora)) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfoWGpl4as5C",
        "colab_type": "text"
      },
      "source": [
        "Comparing the execution time of the query with the regular approach\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_bfT_WyV5tP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9af82ea8-407f-4ab7-d858-825e8bece230"
      },
      "source": [
        "#Execution Time difference\n",
        "t = ot - ora\n",
        "print(\"Execution time difference between our approach and regular approach: \",t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Execution time difference between our approach and regular approach:  0.0017008781433105469\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcpj-QCzl9UI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def join_table_city(join_list):\n",
        "\n",
        "# ************* Join table query *************\n",
        "  queryc = 'SELECT b.NAME, a.post, a.city \\\n",
        "  FROM normal_post_city a \\\n",
        "  INNER JOIN normal_name_post_city b \\\n",
        "  ON a.city = b.city \\\n",
        "  WHERE \\\n",
        "  a.city IN (%s);' \\\n",
        "  % (makeqmarks(len(join_list)))\n",
        "  #print(join_list[0]) # To check the elements in 0th index\n",
        "  return queryc\n",
        "\n",
        "def join_table_post(join_list):\n",
        "\n",
        "# ************* Join table query *************\n",
        "  queryp = 'SELECT b.NAME, a.post, a.city \\\n",
        "  FROM normal_post_city a \\\n",
        "  INNER JOIN normal_name_post_city b \\\n",
        "  ON a.post = b.post \\\n",
        "  WHERE \\\n",
        "  a.post IN (%s);' \\\n",
        "  % (makeqmarks(len(join_list)))\n",
        "  #print(join_list[0]) # To check the elements in 0th index\n",
        "  return queryp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1h-E_pMC69Vl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a61b4802-e739-4832-a08b-b53e0dbd4a32"
      },
      "source": [
        "#join_list = sel_func_post('engineer',t,1)\n",
        "#expected_output_post = ['engineer', 'developer']\n",
        "expected_output_city = ['victoria', 'vancouver', 'ottawa', 'toronto']\n",
        "queryci = join_table_city(expected_output_city)\n",
        "#Query for city\n",
        "tick = time()\n",
        "crsr.execute(queryci, expected_output_city)\n",
        "# crsr.execute(\"SELECT b.NAME, a.post, a.city FROM  normal_post_city a INNER JOIN normal_name_post_city b ON a.city = b.city where a.city IN ('victoria', 'vancouver', 'ottawa', 'toronto')\")\n",
        "tock = time()\n",
        "ora = tock-tick\n",
        "# #To print the query output\n",
        "# for row in crsr.fetchall():\n",
        "#     print (row) \n",
        "print(\"Regular Approach Execution time: \",ora) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Regular Approach Execution time:  0.00064849853515625\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}