{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ykum9sissMgq"
   },
   "source": [
    "Importing all essential libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OQfX9CjYsPga"
   },
   "outputs": [],
   "source": [
    "#Importing all libraries\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import pickle as pickle\n",
    "import subprocess\n",
    "import io\n",
    "from sklearn.decomposition import PCA\n",
    "from itertools import repeat\n",
    "\n",
    "\n",
    "#Optional Libraries\n",
    "#from gensim.models import word2vec\n",
    "#import gensim.downloader as api\n",
    "#from gensim.models import KeyedVectors\n",
    "\n",
    "\n",
    "#Glove pretrained word embeddings: https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UNmVuPrVrvQE"
   },
   "outputs": [],
   "source": [
    "#Connect your drive as file system (If you have your files on drive)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H2phL3B7s5Yv"
   },
   "source": [
    "Word Embeddings part\n",
    "(Pre-trained embeddings used: Glove)\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Reducing the vector dimensions using PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "rSx3vuRJqGdU",
    "outputId": "f4831794-ad2d-44b4-e423-6226c676c4f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove vectors.\n",
      "Done.\n",
      "Reduced the dimensionality of the vector to 10 dimensions! \n",
      "Please check pca_embed2.txt file\n"
     ]
    }
   ],
   "source": [
    "#Reducing Glove word embeddings from 50 to 10 dimensions\n",
    "Glove = {}\n",
    "with io.open('/content/drive/My Drive/NLP_Data/glove.6B.50d.txt', encoding='utf8') as f:\n",
    "#f = open('/content/drive/mydrive/glove.6B.50d.txt')\n",
    "\n",
    "    print(\"Loading Glove vectors.\")\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        Glove[word] = coefs\n",
    "    f.close()\n",
    "\n",
    "    print(\"Done.\")\n",
    "    X_train = []\n",
    "    X_train_names = []\n",
    "    for x in Glove:\n",
    "            X_train.append(Glove[x])\n",
    "            X_train_names.append(x)\n",
    "\n",
    "    X_train = np.asarray(X_train)\n",
    "    pca_embeddings = {}\n",
    "\n",
    "# PCA to get Top Components\n",
    "    pca =  PCA(n_components = 50)\n",
    "    X_train = X_train - np.mean(X_train)\n",
    "    X_fit = pca.fit_transform(X_train)\n",
    "    U1 = pca.components_\n",
    "\n",
    "    z = []\n",
    "\n",
    "# Removing Projections on Top Components\n",
    "    for i, x in enumerate(X_train):\n",
    "\t    for u in U1[0:7]:        \n",
    "        \t    x = x - np.dot(u.transpose(),x) * u \n",
    "\t    z.append(x)\n",
    "\n",
    "    z = np.asarray(z)\n",
    "\n",
    "# PCA Dim Reduction\n",
    "    pca =  PCA(n_components = 10)\n",
    "    X_train = z - np.mean(z)\n",
    "    X_new_final = pca.fit_transform(X_train)\n",
    "\n",
    "\n",
    "# PCA to do Post-Processing Again\n",
    "    pca =  PCA(n_components = 10)\n",
    "    X_new = X_new_final - np.mean(X_new_final)\n",
    "    X_new = pca.fit_transform(X_new)\n",
    "    Ufit = pca.components_\n",
    "\n",
    "    X_new_final = X_new_final - np.mean(X_new_final)\n",
    "\n",
    "    final_pca_embeddings = {}\n",
    "    embedding_file = open('/content/drive/My Drive/NLP_Data/pca_embed2.txt', 'w')\n",
    "\n",
    "    for i, x in enumerate(X_train_names):\n",
    "      final_pca_embeddings[x] = X_new_final[i]\n",
    "      embedding_file.write(\"%s\\t\" % x)\n",
    "      for u in Ufit[0:7]:\n",
    "        final_pca_embeddings[x] = final_pca_embeddings[x] - np.dot(u.transpose(),final_pca_embeddings[x]) * u \n",
    "\n",
    "      for t in final_pca_embeddings[x]:\n",
    "        embedding_file.write(\"%f\\t\" % t)\n",
    "        \n",
    "      embedding_file.write(\"\\n\")\n",
    "\n",
    "\n",
    "    print(\"Reduced the dimensionality of the vector to 10 dimensions! \\nPlease check pca_embed2.txt file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NWptWbI8q9Sf"
   },
   "outputs": [],
   "source": [
    "#Function to get 10 dimensional vector from txt file\n",
    "def get_vector(given_word):\n",
    "  Glove = {}\n",
    "  with io.open('/content/drive/My Drive/NLP_Data/pca_embed2.txt', encoding='utf8') as f:\n",
    "  #f = open('/content/drive/My Drive/NLP_Data/pca_embed2.txt')\n",
    "\n",
    "      #print(\"Loading Glove vectors.\")\n",
    "      for line in f:\n",
    "          values = line.split()\n",
    "          word = values[0]\n",
    "          if word == given_word:\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            given_word_vector = coefs\n",
    "            break\n",
    "  f.close()\n",
    "  return given_word_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QRhXBMkprMHF"
   },
   "outputs": [],
   "source": [
    "#Getting Vectors for available posts\n",
    "engineer_vector = get_vector('engineer')\n",
    "manager_vector = get_vector('manager')\n",
    "developer_vector = get_vector('developer')\n",
    "ceo_vector = get_vector('ceo')\n",
    "cto_vector = get_vector('cto')\n",
    "coo_vector = get_vector('coo')\n",
    "waiter_vector = get_vector('waiter')\n",
    "\n",
    "#Getting Vectors for available cities\n",
    "victoria_vector = get_vector('victoria')\n",
    "vancouver_vector = get_vector('vancouver')\n",
    "delhi_vector = get_vector('delhi')\n",
    "pune_vector = get_vector('pune')\n",
    "ottawa_vector = get_vector('ottawa')\n",
    "toronto_vector = get_vector('toronto')\n",
    "mumbai_vector = get_vector('mumbai')\n",
    "\n",
    "#Stored these vectors in CSV Files\n",
    "#File names:\n",
    "#1. table1_name_post_city.csv\n",
    "#2. table2_vectors_for_post_city.csv\n",
    "#3. table3_vectors_for_posts.csv\n",
    "#4. table4_vectors_for_cities.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YrTl-VK8rMJ7",
    "outputId": "48043406-2963-4f88-e32a-12bb0485f1dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between Engineer and Developer: 0.79248005\n"
     ]
    }
   ],
   "source": [
    "#Defining Cosine Similarity Function\n",
    "def cos_sim(a, b):\n",
    "    \"\"\"Takes 2 vectors a, b and returns the cosine similarity according \n",
    "    to the definition of the dot product\n",
    "    \"\"\"\n",
    "    dot_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    return dot_product / (norm_a * norm_b)\n",
    "\n",
    "#Testing the function\n",
    "similarity = cos_sim(engineer_vector,developer_vector)\n",
    "print(\"Similarity between Engineer and Developer:\",similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Umwm7_4Ns94g"
   },
   "source": [
    "Database creation part\n",
    "\n",
    "---\n",
    "1. Reading data with Pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dkq6wH00rHEA"
   },
   "outputs": [],
   "source": [
    "#Opening & Reading CSV files into pandas dataframe\n",
    "\n",
    "#Dataframe with Person name, Applicable Post and City\n",
    "data = pd.read_csv (r'/content/drive/My Drive/NLP_Data/table1_name_post_city.csv')   \n",
    "df1 = pd.DataFrame(data, columns= ['Name','pi1','pi2','pi3','pi4','pi5','pi6','pi7','pi8','pi9','pi10','ci1','ci2','ci3','ci4','ci5','ci6','ci7','ci8','ci9','ci10'])\n",
    "#print(df1)\n",
    "\n",
    "#Dataframe with Post Available and City\n",
    "data = pd.read_csv (r'/content/drive/My Drive/NLP_Data/table2_vectors_for_post_city.csv')\n",
    "df2 = pd.DataFrame(data, columns= ['pi1','pi2','pi3','pi4','pi5','pi6','pi7','pi8','pi9','pi10','ci1','ci2','ci3','ci4','ci5','ci6','ci7','ci8','ci9','ci10'])\n",
    "#print(df2)\n",
    "\n",
    "#Dataframe with Vectors for respective posts and post\n",
    "data = pd.read_csv (r'/content/drive/My Drive/NLP_Data/table3_vectors_for_posts.csv')   \n",
    "df3 = pd.DataFrame(data, columns= ['pi1','pi2','pi3','pi4','pi5','pi6','pi7','pi8','pi9','pi10','post'])\n",
    "#print(df3)\n",
    "\n",
    "#Dataframe with Vectors for respective cities and city\n",
    "data = pd.read_csv (r'/content/drive/My Drive/NLP_Data/table4_vectors_for_cities.csv')   \n",
    "df4 = pd.DataFrame(data, columns= ['ci1','ci2','ci3','ci4','ci5','ci6','ci7','ci8','ci9','ci10','city'])\n",
    "#print(df4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dsNc_P6vAb43"
   },
   "source": [
    "Database creation part\n",
    "\n",
    "---\n",
    "2. Creating Sqlite database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "OExom1P_1GC1",
    "outputId": "de157dc6-407c-42c8-f6db-345af6c0e099"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 1: Name_Post_City Data\n",
      "('Tom', 0.0, -1e-06, 0.0, 0.0, -1e-06, 1.1e-05, -4e-06, -0.252, 0.00328, 1.39, 0.0, 0.0, 1e-06, -1e-06, -7e-06, 5e-06, 1.2e-05, 0.457, 1.49, 1.24)\n",
      "('Henry', 0.0, -1e-06, 1e-06, 0.0, -4e-06, 5e-06, 1.4999999999999999e-05, 0.478, 0.431, 1.07, 0.0, 1e-06, 0.0, -1e-06, -4e-06, -1e-06, 3e-06, 0.215, 1.22, 0.192)\n",
      "('Bush', 0.0, -1e-06, 1e-06, 0.0, -1e-06, 6e-06, 1.2e-05, 0.32, -0.31, 0.966, 0.0, 1e-06, 0.0, -1e-06, -4e-06, -1e-06, 3e-06, 0.215, 1.22, 0.192)\n",
      "('Ram', 0.0, -1e-06, 1e-06, 0.0, -4e-06, 5e-06, 1.4999999999999999e-05, 0.478, 0.431, 1.07, 0.0, 1e-06, 0.0, -1e-06, -4e-06, -1e-06, 3e-06, 0.215, 1.22, 0.192)\n",
      "('Bharat', 0.0, -2e-06, 2e-06, 0.0, -3e-06, 5e-06, 2.4e-05, 0.733, -0.16899999999999998, 1.06, 0.0, -2e-06, 1e-06, 0.0, 0.0, 8e-06, 2e-06, -0.0689, -0.315, 1.06)\n",
      "('Laxman', 0.0, 0.0, -2e-06, 0.0, -1e-06, 6e-06, -2.2e-05, -0.736, 0.625, 0.428, 0.0, -1e-06, 0.0, 0.0, 0.0, 8e-06, -3e-06, -0.205, -0.23600000000000002, 0.95)\n",
      "('Krishna', 0.0, -2e-06, 2e-06, 0.0, -1e-06, 8e-06, 1.2e-05, 0.28, -0.44, 1.17, 0.0, -1e-06, 0.0, 0.0, -2e-06, 9e-06, 1e-06, -0.0251, 0.397, 1.26)\n",
      "('Josh', 0.0, -1e-06, 0.0, 0.0, 2e-06, 6e-06, -9e-06, -0.424, -0.6579999999999999, 0.485, 0.0, -2e-06, 1e-06, 0.0, 0.0, 8e-06, 2e-06, -0.0689, -0.315, 1.06)\n",
      "('Jelly', 0.0, -1e-06, 1e-06, 0.0, -4e-06, 5e-06, 1.4999999999999999e-05, 0.478, 0.431, 1.07, 0.0, -1e-06, 0.0, 0.0, -2e-06, 9e-06, 1e-06, -0.0251, 0.397, 1.26)\n",
      "('Akash', 0.0, -1e-06, 1e-06, 0.0, -4e-06, 5e-06, 1.4999999999999999e-05, 0.478, 0.431, 1.07, 0.0, 1e-06, -1e-06, -1e-06, -2e-06, 1e-06, -1.1e-05, -0.301, 0.96, 0.179)\n",
      "('Ritul', 0.0, -1e-06, 1e-06, 0.0, -1e-06, 6e-06, 1.2e-05, 0.32, -0.31, 0.966, 0.0, 1e-06, -1e-06, -1e-06, -2e-06, 1e-06, -1.1e-05, -0.301, 0.96, 0.179)\n",
      "('Rosie', 0.0, -1e-06, 1e-06, 0.0, -1e-06, 6e-06, 1.2e-05, 0.32, -0.31, 0.966, 0.0, -1e-06, 0.0, 0.0, -2e-06, 9e-06, 1e-06, -0.0251, 0.397, 1.26)\n",
      "('Alexa', 0.0, -2e-06, 2e-06, 0.0, -3e-06, 5e-06, 2.4e-05, 0.733, -0.16899999999999998, 1.06, 0.0, 1e-06, 0.0, -1e-06, -4e-06, -1e-06, 3e-06, 0.215, 1.22, 0.192)\n",
      "('Sita', 0.0, -1e-06, 0.0, 0.0, -1e-06, 1.1e-05, -4e-06, -0.252, 0.00328, 1.39, 0.0, 1e-06, 0.0, -1e-06, -5e-06, 0.0, 7e-06, 0.324, 1.28, 0.47200000000000003)\n",
      "('Erik', 0.0, -1e-06, 0.0, 0.0, -1e-06, 1.1e-05, -4e-06, -0.252, 0.00328, 1.39, 0.0, 1e-06, -1e-06, -1e-06, -2e-06, 1e-06, -1.1e-05, -0.301, 0.96, 0.179)\n",
      "('Deepika', 0.0, -1e-06, 1e-06, 0.0, -4e-06, 5e-06, 1.4999999999999999e-05, 0.478, 0.431, 1.07, 0.0, -2e-06, 1e-06, 0.0, 0.0, 8e-06, 2e-06, -0.0689, -0.315, 1.06)\n",
      "('Jerry', 0.0, -1e-06, 0.0, 0.0, 2e-06, 6e-06, -9e-06, -0.424, -0.6579999999999999, 0.485, 0.0, 1e-06, 0.0, -1e-06, -4e-06, -1e-06, 3e-06, 0.215, 1.22, 0.192)\n",
      "('Angelina', 0.0, -1e-06, 1e-06, 0.0, -1e-06, 6e-06, 1.2e-05, 0.32, -0.31, 0.966, 0.0, 1e-06, -1e-06, -1e-06, -2e-06, 1e-06, -1.1e-05, -0.301, 0.96, 0.179)\n",
      "('Selena', 0.0, -1e-06, 0.0, 0.0, -1e-06, 1.1e-05, -4e-06, -0.252, 0.00328, 1.39, 0.0, 1e-06, -1e-06, -1e-06, -2e-06, 1e-06, -1.1e-05, -0.301, 0.96, 0.179)\n",
      "\n",
      "Table 2: Post_City Data\n",
      "(0.0, -1e-06, 0.0, 0.0, -1e-06, 1.1e-05, -4e-06, -0.252, 0.00328, 1.39, 0.0, 0.0, 1e-06, -1e-06, -7e-06, 5e-06, 1.2e-05, 0.457, 1.49, 1.24)\n",
      "(0.0, -1e-06, 1e-06, 0.0, -4e-06, 5e-06, 1.4999999999999999e-05, 0.478, 0.431, 1.07, 0.0, 0.0, 1e-06, -1e-06, -7e-06, 5e-06, 1.2e-05, 0.457, 1.49, 1.24)\n",
      "(0.0, -1e-06, 1e-06, 0.0, -4e-06, 5e-06, 1.4999999999999999e-05, 0.478, 0.431, 1.07, 0.0, -1e-06, 0.0, 0.0, 0.0, 8e-06, -3e-06, -0.205, -0.23600000000000002, 0.95)\n",
      "(0.0, -1e-06, 0.0, 0.0, -1e-06, 1.1e-05, -4e-06, -0.252, 0.00328, 1.39, 0.0, -1e-06, 0.0, 0.0, -2e-06, 9e-06, 1e-06, -0.0251, 0.397, 1.26)\n",
      "(0.0, -1e-06, 1e-06, 0.0, -1e-06, 6e-06, 1.2e-05, 0.32, -0.31, 0.966, 0.0, 1e-06, -1e-06, -1e-06, -2e-06, 1e-06, -1.1e-05, -0.301, 0.96, 0.179)\n",
      "(0.0, -2e-06, 2e-06, 0.0, -3e-06, 5e-06, 2.4e-05, 0.733, -0.16899999999999998, 1.06, 0.0, 1e-06, 0.0, -1e-06, -5e-06, 0.0, 7e-06, 0.324, 1.28, 0.47200000000000003)\n",
      "(0.0, -1e-06, 1e-06, 0.0, -1e-06, 6e-06, 1.2e-05, 0.32, -0.31, 0.966, 0.0, 1e-06, 0.0, -1e-06, -4e-06, -1e-06, 3e-06, 0.215, 1.22, 0.192)\n",
      "(0.0, -1e-06, 0.0, 0.0, 2e-06, 6e-06, -9e-06, -0.424, -0.6579999999999999, 0.485, 0.0, 1e-06, -1e-06, -1e-06, -2e-06, 1e-06, -1.1e-05, -0.301, 0.96, 0.179)\n",
      "(0.0, -1e-06, 1e-06, 0.0, -4e-06, 5e-06, 1.4999999999999999e-05, 0.478, 0.431, 1.07, 0.0, -2e-06, 1e-06, 0.0, 0.0, 8e-06, 2e-06, -0.0689, -0.315, 1.06)\n",
      "(0.0, -1e-06, 1e-06, 0.0, -1e-06, 6e-06, 1.2e-05, 0.32, -0.31, 0.966, 0.0, -1e-06, 0.0, 0.0, 0.0, 8e-06, -3e-06, -0.205, -0.23600000000000002, 0.95)\n",
      "(0.0, -1e-06, 1e-06, 0.0, -1e-06, 6e-06, 1.2e-05, 0.32, -0.31, 0.966, 0.0, -1e-06, 0.0, 0.0, 0.0, 8e-06, -3e-06, -0.205, -0.23600000000000002, 0.95)\n",
      "(0.0, -1e-06, 1e-06, 0.0, -4e-06, 5e-06, 1.4999999999999999e-05, 0.478, 0.431, 1.07, 0.0, -2e-06, 1e-06, 0.0, 0.0, 8e-06, 2e-06, -0.0689, -0.315, 1.06)\n",
      "(0.0, -1e-06, 1e-06, 0.0, -1e-06, 6e-06, 1.2e-05, 0.32, -0.31, 0.966, 0.0, 1e-06, -1e-06, -1e-06, -2e-06, 1e-06, -1.1e-05, -0.301, 0.96, 0.179)\n",
      "(0.0, -2e-06, 2e-06, 0.0, -3e-06, 5e-06, 2.4e-05, 0.733, -0.16899999999999998, 1.06, 0.0, -1e-06, 0.0, 0.0, 0.0, 8e-06, -3e-06, -0.205, -0.23600000000000002, 0.95)\n",
      "(0.0, -1e-06, 0.0, 0.0, 2e-06, 6e-06, -9e-06, -0.424, -0.6579999999999999, 0.485, 0.0, -1e-06, 0.0, 0.0, 0.0, 8e-06, -3e-06, -0.205, -0.23600000000000002, 0.95)\n",
      "(0.0, -1e-06, 1e-06, 0.0, -4e-06, 5e-06, 1.4999999999999999e-05, 0.478, 0.431, 1.07, 0.0, 1e-06, 0.0, -1e-06, -5e-06, 0.0, 7e-06, 0.324, 1.28, 0.47200000000000003)\n",
      "(0.0, -1e-06, 1e-06, 0.0, -1e-06, 6e-06, 1.2e-05, 0.32, -0.31, 0.966, 0.0, -2e-06, 1e-06, 0.0, 0.0, 8e-06, 2e-06, -0.0689, -0.315, 1.06)\n",
      "(0.0, -1e-06, 1e-06, 0.0, -1e-06, 6e-06, 1.2e-05, 0.32, -0.31, 0.966, 0.0, 1e-06, -1e-06, -1e-06, -2e-06, 1e-06, -1.1e-05, -0.301, 0.96, 0.179)\n",
      "(0.0, -1e-06, 1e-06, 0.0, -4e-06, 5e-06, 1.4999999999999999e-05, 0.478, 0.431, 1.07, 0.0, 1e-06, -1e-06, -1e-06, -2e-06, 1e-06, -1.1e-05, -0.301, 0.96, 0.179)\n",
      "(0.0, -1e-06, 1e-06, 0.0, -4e-06, 5e-06, 1.4999999999999999e-05, 0.478, 0.431, 1.07, 0.0, 1e-06, 0.0, -1e-06, -4e-06, -1e-06, 3e-06, 0.215, 1.22, 0.192)\n",
      "(0.0, -1e-06, 1e-06, 0.0, -1e-06, 6e-06, 1.2e-05, 0.32, -0.31, 0.966, 0.0, -1e-06, 0.0, 0.0, -2e-06, 9e-06, 1e-06, -0.0251, 0.397, 1.26)\n",
      "(0.0, -1e-06, 0.0, 0.0, -1e-06, 1.1e-05, -4e-06, -0.252, 0.00328, 1.39, 0.0, -2e-06, 1e-06, 0.0, 0.0, 8e-06, 2e-06, -0.0689, -0.315, 1.06)\n",
      "\n",
      "Table 3: Em_Post_Name Data\n",
      "(0.0, -1e-06, 1e-06, 0.0, -1e-06, 6e-06, 1.2e-05, 0.32, -0.31, 0.966, 'engineer')\n",
      "(0.0, -1e-06, 1e-06, 0.0, -4e-06, 5e-06, 1.4999999999999999e-05, 0.478, 0.431, 1.07, 'developer')\n",
      "(0.0, -1e-06, 0.0, 0.0, -1e-06, 1.1e-05, -4e-06, -0.252, 0.00328, 1.39, 'manager')\n",
      "(0.0, -1e-06, 0.0, 0.0, 2e-06, 6e-06, -9e-06, -0.424, -0.6579999999999999, 0.485, 'coo')\n",
      "(0.0, 0.0, -2e-06, 0.0, -1e-06, 6e-06, -2.2e-05, -0.736, 0.625, 0.428, 'cto')\n",
      "(0.0, -2e-06, 2e-06, 0.0, -3e-06, 5e-06, 2.4e-05, 0.733, -0.16899999999999998, 1.06, 'ceo')\n",
      "(0.0, -2e-06, 2e-06, 0.0, -1e-06, 8e-06, 1.2e-05, 0.28, -0.44, 1.17, 'waiter')\n",
      "\n",
      "Table 4: Em_City_Name Data\n",
      "(0.0, 0.0, 1e-06, -1e-06, -7e-06, 5e-06, 1.2e-05, 0.457, 1.49, 1.24, 'victoria')\n",
      "(0.0, 1e-06, 0.0, -1e-06, -4e-06, -1e-06, 3e-06, 0.215, 1.22, 0.192, 'vancouver')\n",
      "(0.0, -1e-06, 0.0, 0.0, -2e-06, 9e-06, 1e-06, -0.0251, 0.397, 1.26, 'mumbai')\n",
      "(0.0, -2e-06, 1e-06, 0.0, 0.0, 8e-06, 2e-06, -0.0689, -0.315, 1.06, 'delhi')\n",
      "(0.0, -1e-06, 0.0, 0.0, 0.0, 8e-06, -3e-06, -0.205, -0.23600000000000002, 0.95, 'pune')\n",
      "(0.0, 1e-06, -1e-06, -1e-06, -2e-06, 1e-06, -1.1e-05, -0.301, 0.96, 0.179, 'ottawa')\n",
      "(0.0, 1e-06, 0.0, -1e-06, -5e-06, 0.0, 7e-06, 0.324, 1.28, 0.47200000000000003, 'toronto')\n"
     ]
    }
   ],
   "source": [
    "#Creating database\n",
    "connection = sqlite3.connect(\"position_city_database_with_embeddings.db\") \n",
    "crsr = connection.cursor() \n",
    "\n",
    "#Comment the table creation and insertion of data into the table if the database is already created once.\n",
    "\n",
    "#Creating table1 with name, embeddings of post, and embeddings of city\n",
    "crsr.execute('CREATE TABLE name_post_city (NAME nvarchar(50),pi1 float,pi2 float,pi3 float,pi4 float,pi5 float,pi6 float,pi7 float,pi8 float,pi9 float,pi10 float, ci1 float,ci2 float,ci3 float,ci4 float,ci5 float,ci6 float,ci7 float,ci8 float,ci9 float,ci10 float, FOREIGN KEY (ci1,ci2,ci3,ci4,ci5,ci6,ci7,ci8,ci9,ci10) REFERENCES em_city_name(ci1,ci2,ci3,ci4,ci5,ci6,ci7,ci8,ci9,ci10), FOREIGN KEY (pi1,pi2,pi3,pi4,pi5,pi6,pi7,pi8,pi9,pi10) REFERENCES em_post_city(pi1,pi2,pi3,pi4,pi5,pi6,pi7,pi8,pi9,pi10))')\n",
    "df1.to_sql('name_post_city', connection, if_exists='replace', index = False)\n",
    "crsr.execute('''SELECT * FROM name_post_city''')\n",
    "print(\"Table 1: Name_Post_City Data\")\n",
    "for row in crsr.fetchall():\n",
    "    print (row)\n",
    "\n",
    "#Creating table2 with embeddings of post and embeddings of city\n",
    "crsr.execute('CREATE TABLE post_city (ci1 float,ci2 float,ci3 float,ci4 float,ci5 float,ci6 float,ci7 float,ci8 float,ci9 float,ci10 float,post nvarchar(50), FOREIGN KEY (ci1,ci2,ci3,ci4,ci5,ci6,ci7,ci8,ci9,ci10) REFERENCES em_city_name(ci1,ci2,ci3,ci4,ci5,ci6,ci7,ci8,ci9,ci10))')\n",
    "df2.to_sql('post_city', connection, if_exists='replace', index = False)\n",
    "print(\"\\nTable 2: Post_City Data\")\n",
    "crsr.execute('''SELECT * FROM post_city''')\n",
    "for row in crsr.fetchall():\n",
    "    print (row)\n",
    "\n",
    "#Creating table3 with embeddings of post and name of posts\n",
    "crsr.execute('CREATE TABLE em_post_name (pi1 float,pi2 float,pi3 float,pi4 float,pi5 float,pi6 float,pi7 float,pi8 float,pi9 float,pi10 float, post nvarchar(50), PRIMARY KEY(pi1,pi2,pi3,pi4,pi5,pi6,pi7,pi8,pi9,pi10))')\n",
    "df3.to_sql('em_post_name', connection, if_exists='replace', index = False)\n",
    "print(\"\\nTable 3: Em_Post_Name Data\")\n",
    "crsr.execute('''SELECT * FROM em_post_name''')\n",
    "for row in crsr.fetchall():\n",
    "    print (row)\n",
    "\n",
    "#Creating table4 with embeddings of city and name of cities\n",
    "crsr.execute('CREATE TABLE em_city_name (ci1 float,ci2 float,ci3 float,ci4 float,ci5 float,ci6 float,ci7 float,ci8 float,ci9 float,ci10 float, city nvarchar(50), PRIMARY KEY(ci1,ci2,ci3,ci4,ci5,ci6,ci7,ci8,ci9,ci10))')\n",
    "df4.to_sql('em_city_name', connection, if_exists='replace', index = False)\n",
    "print(\"\\nTable 4: Em_City_Name Data\")\n",
    "crsr.execute('''SELECT * FROM em_city_name''')\n",
    "for row in crsr.fetchall():\n",
    "    print (row)\n",
    "\n",
    "connection.commit()\n",
    "\n",
    "#Execute the following line to print all the SQL queries when executed\n",
    "#connection.set_trace_callback(print)\n",
    "\n",
    "#Incase you want to drop all tables:\n",
    "#crsr.execute('DROP TABLE name_post_city')\n",
    "#crsr.execute('DROP TABLE post_city')\n",
    "#crsr.execute('DROP TABLE em_post_name')\n",
    "#crsr.execute('DROP TABLE em_city_name')\n",
    "#connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A8YMJdSCAo9l"
   },
   "source": [
    "Function for calculating cosine similarity on:\n",
    "\n",
    "---\n",
    "1. Posts (Engineer, Developer, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "dXcWiAVn5wvn",
    "outputId": "b57cd81b-23e2-4949-a5c6-f5a5272a9cda"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 0.0, 0.0, 0.0),\n",
       " (-1e-06, -1e-06, -2e-06, -2e-06),\n",
       " (1e-06, 1e-06, 2e-06, 2e-06),\n",
       " (0.0, 0.0, 0.0, 0.0),\n",
       " (-1e-06, -4e-06, -3e-06, -1e-06),\n",
       " (6e-06, 5e-06, 5e-06, 8e-06),\n",
       " (1.2e-05, 1.4999999999999999e-05, 2.4e-05, 1.2e-05),\n",
       " (0.32, 0.478, 0.733, 0.28),\n",
       " (-0.31, 0.431, -0.16899999999999998, -0.44),\n",
       " (0.966, 1.07, 1.06, 1.17)]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connection = sqlite3.connect(\"position_city_database_with_embeddings.db\") \n",
    "crsr = connection.cursor() \n",
    "\n",
    "\n",
    "def sel_func_post(q,threshold):\n",
    "  crsr.execute(\"select pi1,pi2,pi3,pi4,pi5,pi6,pi7,pi8,pi9,pi10 from em_post_name where post ='%s'\" %q)\n",
    "  q_vect = crsr.fetchall()\n",
    "  crsr.execute(\"select pi1,pi2,pi3,pi4,pi5,pi6,pi7,pi8,pi9,pi10,post from em_post_name\")\n",
    "  t_vect = crsr.fetchall()\n",
    "  vect_t = [tuple(list(x)[0:10]) for x in t_vect] # Getting all vectors in em_post_name\n",
    "  vect_names = [list(x).pop(-1) for x in t_vect] # Getting all the corresponding post names to the vectors\n",
    "  #print(vect_t) # Used to print all vectors in em_post_name\n",
    "  #print(vect_names) # Used to print all the corresponding posts to the vectors\n",
    "  similarity_array = [cos_sim(q_vect, x)[0] for x in vect_t] # Getting similarity scores for all vectors in table\n",
    "  #print(similarity_array) # Used to print similary between vectors\n",
    "  a = np.array(similarity_array)\n",
    "  index = np.where(a > threshold)[0] # Getting index of all the post which are having similar value > threshold\n",
    "  #print(index) # Printing indexes \n",
    "  new_vect_t = [vect_t[x] for x in index] # Getting new vectors according to those indexes\n",
    "  #print(new_vect_t) # Printing the new vector\n",
    "  #print(list(np.array(vect_t)[index][0])) # Checking the element\n",
    "  join_list = []\n",
    "  for x in range(0,len(new_vect_t[0])):\n",
    "    join_list.append(tuple([i[x] for i in new_vect_t])) # Joining the new vectors together in a list\n",
    "  #print(join_list) # To print the join_list\n",
    "  return join_list # Returning the join_list\n",
    "\n",
    "# Executing the function\n",
    "\n",
    "t = 0.85 # Defining threshold (You can change according to your requirements)\n",
    "sel_func_post('ceo',t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x8WnWEImA2YH"
   },
   "source": [
    "Function for calculating cosine similarity on:\n",
    "\n",
    "---\n",
    "2. Cities (Victoria, Pune, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "SXbvP13TH7jd",
    "outputId": "dd5e9893-6706-4df4-ee9d-1b46efebd134"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 0.0, 0.0),\n",
       " (0.0, 1e-06, 1e-06),\n",
       " (1e-06, 0.0, 0.0),\n",
       " (-1e-06, -1e-06, -1e-06),\n",
       " (-7e-06, -4e-06, -5e-06),\n",
       " (5e-06, -1e-06, 0.0),\n",
       " (1.2e-05, 3e-06, 7e-06),\n",
       " (0.457, 0.215, 0.324),\n",
       " (1.49, 1.22, 1.28),\n",
       " (1.24, 0.192, 0.47200000000000003)]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sel_func_city(q,threshold):\n",
    "  crsr.execute(\"select ci1,ci2,ci3,ci4,ci5,ci6,ci7,ci8,ci9,ci10 from em_city_name where city ='%s'\" %q)\n",
    "  q_vect = crsr.fetchall()\n",
    "  crsr.execute(\"select ci1,ci2,ci3,ci4,ci5,ci6,ci7,ci8,ci9,ci10,city from em_city_name\")\n",
    "  t_vect = crsr.fetchall()\n",
    "  vect_t = [tuple(list(x)[0:10]) for x in t_vect] # Getting all vectors in em_city_name\n",
    "  vect_names = [list(x).pop(-1) for x in t_vect] # Getting all the corresponding city names to the vectors\n",
    "  #print(vect_t) # Used to print all vectors in em_post_name\n",
    "  #print(vect_names) # Used to print all the corresponding posts to the vectors\n",
    "  similarity_array = [cos_sim(q_vect, x)[0] for x in vect_t] # Getting similarity scores for all vectors in table\n",
    "  #print(similarity_array) # Used to print similary between vectors\n",
    "  a = np.array(similarity_array) \n",
    "  index = np.where(a > threshold)[0] # Getting index of all the post which are having similar value > threshold\n",
    "  #print(index) # Printing indexes \n",
    "  new_vect_t = [vect_t[x] for x in index] # Getting new vectors according to those indexes\n",
    "  #print(new_vect_t) # Printing the new vector\n",
    "  #print(list(np.array(vect_t)[index][0])) # Checking the element\n",
    "  join_list = []\n",
    "  for x in range(0,len(new_vect_t[0])):\n",
    "    join_list.append(tuple([i[x] for i in new_vect_t]))  # Joining the new vectors together in a list\n",
    "  #print(join_list) # To print the join_list\n",
    "  return join_list # Returning the join_list\n",
    "\n",
    "# Executing the function\n",
    "\n",
    "t = 0.85 # Defining threshold (You can change according to your requirements)\n",
    "sel_func_city('victoria',t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SlJ7PJMQBErV"
   },
   "source": [
    "Joining two tables according to word cosine similarities\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "YSAMjVi1cl03",
    "outputId": "f48ac402-c9f0-4787-dc81-d940381a6c5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Tom', 'manager', 'victoria')\n",
      "('Tom', 'developer', 'victoria')\n",
      "('Sita', 'ceo', 'toronto')\n",
      "('Alexa', 'engineer', 'vancouver')\n",
      "('Bush', 'engineer', 'vancouver')\n",
      "('Henry', 'engineer', 'vancouver')\n",
      "('Jerry', 'engineer', 'vancouver')\n",
      "('Ram', 'engineer', 'vancouver')\n",
      "('Sita', 'developer', 'toronto')\n",
      "('Alexa', 'developer', 'vancouver')\n",
      "('Bush', 'developer', 'vancouver')\n",
      "('Henry', 'developer', 'vancouver')\n",
      "('Jerry', 'developer', 'vancouver')\n",
      "('Ram', 'developer', 'vancouver')\n"
     ]
    }
   ],
   "source": [
    "connection = sqlite3.connect(\"position_city_database_with_embeddings.db\") \n",
    "crsr = connection.cursor() \n",
    "\n",
    "def makeqmarks(i):\n",
    "    return ', '.join(repeat('?', i))\n",
    "\n",
    "#placeholder = '?'\n",
    "#format_strings = ','.join(['%s'] * len(join_list[0]))\n",
    "\n",
    "# ************* Getting Joined List *************\n",
    "\n",
    "join_list = sel_func_city('victoria', 0.85) # Getting locations which having similarity score of more than .85 with 'Victoria'\n",
    "#print(join_list)\n",
    "\n",
    "# **************************\n",
    "\n",
    "# ************* Join table query *************\n",
    "\n",
    "query = 'SELECT b.name, d.post, c.city \\\n",
    "FROM em_post_name d, em_city_name c, post_city a \\\n",
    "INNER JOIN name_post_city b \\\n",
    "ON a.ci1 = b.ci1 AND \\\n",
    "a.ci2 = b.ci2 AND \\\n",
    "a.ci3 = b.ci3 AND \\\n",
    "a.ci4 = b.ci4 AND \\\n",
    "a.ci5 = b.ci5 AND \\\n",
    "a.ci6 = b.ci6 AND \\\n",
    "a.ci7 = b.ci7 AND \\\n",
    "a.ci8 = b.ci8 AND \\\n",
    "a.ci9 = b.ci9 AND \\\n",
    "a.ci10 = b.ci10 \\\n",
    "WHERE \\\n",
    "a.ci1 = c.ci1 AND \\\n",
    "a.ci2 = c.ci2 AND \\\n",
    "a.ci3 = c.ci3 AND \\\n",
    "a.ci4 = c.ci4 AND \\\n",
    "a.ci5 = c.ci5 AND \\\n",
    "a.ci6 = c.ci6 AND \\\n",
    "a.ci7 = c.ci7 AND \\\n",
    "a.ci8 = c.ci8 AND \\\n",
    "a.ci9 = c.ci9 AND \\\n",
    "a.ci10 = c.ci10 AND \\\n",
    "a.pi1 = d.pi1 AND \\\n",
    "a.pi2 = d.pi2 AND \\\n",
    "a.pi3 = d.pi3 AND \\\n",
    "a.pi4 = d.pi4 AND \\\n",
    "a.pi5 = d.pi5 AND \\\n",
    "a.pi6 = d.pi6 AND \\\n",
    "a.pi7 = d.pi7 AND \\\n",
    "a.pi8 = d.pi8 AND \\\n",
    "a.pi9 = d.pi9 AND \\\n",
    "a.pi10 = d.pi10 AND \\\n",
    "a.ci1 IN (%s) AND \\\n",
    "a.ci2 IN (%s) AND \\\n",
    "a.ci3 IN (%s) AND \\\n",
    "a.ci4 IN (%s) AND \\\n",
    "a.ci5 IN (%s) AND \\\n",
    "a.ci6 IN (%s) AND \\\n",
    "a.ci7 IN (%s) AND \\\n",
    "a.ci8 IN (%s) AND \\\n",
    "a.ci9 IN (%s) AND \\\n",
    "a.ci10 IN (%s);' \\\n",
    "% (makeqmarks(len(join_list[0])), makeqmarks(len(join_list[1])), makeqmarks(len(join_list[2])),makeqmarks(len(join_list[3])),makeqmarks(len(join_list[4])),makeqmarks(len(join_list[5])),makeqmarks(len(join_list[6])),makeqmarks(len(join_list[7])),makeqmarks(len(join_list[8])),makeqmarks(len(join_list[9])))\n",
    "#print(join_list[0]) # To check the elements in 0th index\n",
    "\n",
    "# **************************\n",
    "\n",
    "# ************* Executing and Displaying the Query *************\n",
    "\n",
    "crsr.execute(query, join_list[0] + join_list[1] + join_list[2] + join_list[3] + join_list[4] + join_list[5] + join_list[6] + join_list[7] + join_list[8] + join_list[9])\n",
    "for row in crsr.fetchall():\n",
    "    print (row)\n",
    "\n",
    "# **************************\n",
    "\n",
    "# Actual Generated Query\n",
    "# SELECT b.name, c.city, d.post FROM em_city_name c, em_post_name d, post_city a INNER JOIN name_post_city b ON a.ci1 = b.ci1 AND a.ci2 = b.ci2 AND a.ci3 = b.ci3 AND a.ci4 = b.ci4 AND a.ci5 = b.ci5 AND a.ci6 = b.ci6 AND a.ci7 = b.ci7 AND a.ci8 = b.ci8 AND a.ci9 = b.ci9 AND a.ci10 = b.ci10 WHERE a.ci1 IN (0.0, 0.0, 0.0) AND a.ci2 IN (0.0, 1.0e-06, 1.0e-06) AND a.ci3 IN (1.0e-06, 0.0, 0.0) AND a.ci4 IN (-1.0e-06, -1.0e-06, -1.0e-06) AND a.ci5 IN (-7.0e-06, -4.0e-06, -5.0e-06) AND a.ci6 IN (5.0e-06, -1.0e-06, 0.0) AND a.ci7 IN (1.2e-05, 3.0e-06, 7.0e-06) AND a.ci8 IN (0.457, 0.215, 0.324) AND a.ci9 IN (1.49, 1.22, 1.28) AND a.ci10 IN (1.24, 0.192, 0.472);"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NLP_Database_Fusion_Single_Words.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
